{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\angang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\angang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\angang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\angang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\angang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\angang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download(['punkt', 'stopwords', 'wordnet', 'averaged_perceptron_tagger', 'maxent_ne_chunker', 'words'])\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import ne_chunk\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# !pip install -U spacy\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download en_core_web_lg\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "4  12  says: west side of Haiti, rest of the country ...   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct        1   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct        1   \n",
       "4  facade ouest d Haiti et le reste du pays aujou...  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products      ...        \\\n",
       "0        0      0            0             0                 0      ...         \n",
       "1        0      0            1             0                 0      ...         \n",
       "2        0      0            0             0                 0      ...         \n",
       "3        1      0            1             0                 1      ...         \n",
       "4        0      0            0             0                 0      ...         \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "2            0                     0                0       0      0     0   \n",
       "3            0                     0                0       0      0     0   \n",
       "4            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "2           0     0              0              0  \n",
       "3           0     0              0              0  \n",
       "4           0     0              0              0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///../data/DisasterResponse.db')\n",
    "df = pd.read_sql_table('Message', con=engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['message']\n",
    "Y = df[df.columns[4:]]\n",
    "# X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    '''\n",
    "    Tokenize text.\n",
    "    \n",
    "    INPUT\n",
    "        text (str): text to be tokenized\n",
    "    OUTPUT\n",
    "        tokens (list): list of tokens\n",
    "    '''\n",
    "    # Normalize text\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    # Tokenize text\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "    \n",
    "    # Reduce words to their root forms\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(w).lower().strip() for w in words]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# # Sanity check\n",
    "# tokenize(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine learning pipeline takes in the `message` column as input and outputs classification results on the other 36 categories in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier(n_estimators=10))),\n",
    "])\n",
    "\n",
    "# # View parameters in pipeline\n",
    "# pipeline.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip..._score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=None))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test model\n",
    "Report the f1 score, precision and recall for each output category of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions based on the trained model\n",
    "Y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category: related -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.36      0.45      2034\n",
      "           1       0.82      0.93      0.87      6617\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      8651\n",
      "   macro avg       0.72      0.64      0.66      8651\n",
      "weighted avg       0.77      0.80      0.77      8651\n",
      "\n",
      "\n",
      "Category: request -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93      7201\n",
      "           1       0.83      0.38      0.52      1450\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      8651\n",
      "   macro avg       0.86      0.68      0.73      8651\n",
      "weighted avg       0.88      0.88      0.86      8651\n",
      "\n",
      "\n",
      "Category: offer -----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angang\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8610\n",
      "           1       0.00      0.00      0.00        41\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      8651\n",
      "   macro avg       0.50      0.50      0.50      8651\n",
      "weighted avg       0.99      1.00      0.99      8651\n",
      "\n",
      "\n",
      "Category: aid_related -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.88      0.79      5044\n",
      "           1       0.75      0.51      0.61      3607\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      8651\n",
      "   macro avg       0.73      0.69      0.70      8651\n",
      "weighted avg       0.73      0.73      0.71      8651\n",
      "\n",
      "\n",
      "Category: medical_help -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      7957\n",
      "           1       0.66      0.09      0.16       694\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      8651\n",
      "   macro avg       0.79      0.54      0.56      8651\n",
      "weighted avg       0.90      0.92      0.90      8651\n",
      "\n",
      "\n",
      "Category: medical_products -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      8210\n",
      "           1       0.72      0.08      0.15       441\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      8651\n",
      "   macro avg       0.84      0.54      0.56      8651\n",
      "weighted avg       0.94      0.95      0.93      8651\n",
      "\n",
      "\n",
      "Category: search_and_rescue -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      8409\n",
      "           1       0.62      0.04      0.08       242\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      8651\n",
      "   macro avg       0.80      0.52      0.53      8651\n",
      "weighted avg       0.96      0.97      0.96      8651\n",
      "\n",
      "\n",
      "Category: security -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      8481\n",
      "           1       0.00      0.00      0.00       170\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      8651\n",
      "   macro avg       0.49      0.50      0.50      8651\n",
      "weighted avg       0.96      0.98      0.97      8651\n",
      "\n",
      "\n",
      "Category: military -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      8386\n",
      "           1       0.53      0.04      0.07       265\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      8651\n",
      "   macro avg       0.75      0.52      0.53      8651\n",
      "weighted avg       0.96      0.97      0.96      8651\n",
      "\n",
      "\n",
      "Category: child_alone -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8651\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      8651\n",
      "   macro avg       1.00      1.00      1.00      8651\n",
      "weighted avg       1.00      1.00      1.00      8651\n",
      "\n",
      "\n",
      "Category: water -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      8109\n",
      "           1       0.81      0.21      0.33       542\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      8651\n",
      "   macro avg       0.88      0.60      0.65      8651\n",
      "weighted avg       0.94      0.95      0.93      8651\n",
      "\n",
      "\n",
      "Category: food -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      7701\n",
      "           1       0.81      0.35      0.49       950\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      8651\n",
      "   macro avg       0.87      0.67      0.72      8651\n",
      "weighted avg       0.91      0.92      0.91      8651\n",
      "\n",
      "\n",
      "Category: shelter -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      7866\n",
      "           1       0.84      0.17      0.29       785\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      8651\n",
      "   macro avg       0.88      0.59      0.62      8651\n",
      "weighted avg       0.92      0.92      0.90      8651\n",
      "\n",
      "\n",
      "Category: clothing -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      8528\n",
      "           1       1.00      0.11      0.20       123\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      8651\n",
      "   macro avg       0.99      0.56      0.60      8651\n",
      "weighted avg       0.99      0.99      0.98      8651\n",
      "\n",
      "\n",
      "Category: money -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      8456\n",
      "           1       0.83      0.03      0.05       195\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      8651\n",
      "   macro avg       0.91      0.51      0.52      8651\n",
      "weighted avg       0.97      0.98      0.97      8651\n",
      "\n",
      "\n",
      "Category: missing_people -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      8547\n",
      "           1       0.00      0.00      0.00       104\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      8651\n",
      "   macro avg       0.49      0.50      0.50      8651\n",
      "weighted avg       0.98      0.99      0.98      8651\n",
      "\n",
      "\n",
      "Category: refugees -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      8344\n",
      "           1       0.60      0.05      0.09       307\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      8651\n",
      "   macro avg       0.78      0.52      0.54      8651\n",
      "weighted avg       0.95      0.97      0.95      8651\n",
      "\n",
      "\n",
      "Category: death -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      8240\n",
      "           1       0.83      0.10      0.17       411\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      8651\n",
      "   macro avg       0.90      0.55      0.58      8651\n",
      "weighted avg       0.95      0.96      0.94      8651\n",
      "\n",
      "\n",
      "Category: other_aid -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      7491\n",
      "           1       0.63      0.03      0.06      1160\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      8651\n",
      "   macro avg       0.75      0.52      0.50      8651\n",
      "weighted avg       0.84      0.87      0.81      8651\n",
      "\n",
      "\n",
      "Category: infrastructure_related -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      8100\n",
      "           1       0.47      0.01      0.02       551\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      8651\n",
      "   macro avg       0.70      0.51      0.50      8651\n",
      "weighted avg       0.91      0.94      0.91      8651\n",
      "\n",
      "\n",
      "Category: transport -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      8266\n",
      "           1       0.70      0.06      0.11       385\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      8651\n",
      "   macro avg       0.83      0.53      0.54      8651\n",
      "weighted avg       0.95      0.96      0.94      8651\n",
      "\n",
      "\n",
      "Category: buildings -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      8202\n",
      "           1       0.75      0.09      0.16       449\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      8651\n",
      "   macro avg       0.85      0.54      0.57      8651\n",
      "weighted avg       0.94      0.95      0.93      8651\n",
      "\n",
      "\n",
      "Category: electricity -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      8471\n",
      "           1       1.00      0.03      0.05       180\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      8651\n",
      "   macro avg       0.99      0.51      0.52      8651\n",
      "weighted avg       0.98      0.98      0.97      8651\n",
      "\n",
      "\n",
      "Category: tools -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      8596\n",
      "           1       0.00      0.00      0.00        55\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      8651\n",
      "   macro avg       0.50      0.50      0.50      8651\n",
      "weighted avg       0.99      0.99      0.99      8651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Category: hospitals -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      8569\n",
      "           1       0.00      0.00      0.00        82\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      8651\n",
      "   macro avg       0.50      0.50      0.50      8651\n",
      "weighted avg       0.98      0.99      0.99      8651\n",
      "\n",
      "\n",
      "Category: shops -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8615\n",
      "           1       0.00      0.00      0.00        36\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      8651\n",
      "   macro avg       0.50      0.50      0.50      8651\n",
      "weighted avg       0.99      1.00      0.99      8651\n",
      "\n",
      "\n",
      "Category: aid_centers -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      8543\n",
      "           1       0.00      0.00      0.00       108\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      8651\n",
      "   macro avg       0.49      0.50      0.50      8651\n",
      "weighted avg       0.98      0.99      0.98      8651\n",
      "\n",
      "\n",
      "Category: other_infrastructure -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      8279\n",
      "           1       0.33      0.01      0.01       372\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      8651\n",
      "   macro avg       0.65      0.50      0.49      8651\n",
      "weighted avg       0.93      0.96      0.94      8651\n",
      "\n",
      "\n",
      "Category: weather_related -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      6202\n",
      "           1       0.86      0.54      0.66      2449\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      8651\n",
      "   macro avg       0.85      0.75      0.78      8651\n",
      "weighted avg       0.85      0.84      0.83      8651\n",
      "\n",
      "\n",
      "Category: floods -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      7914\n",
      "           1       0.88      0.21      0.34       737\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      8651\n",
      "   macro avg       0.91      0.60      0.65      8651\n",
      "weighted avg       0.93      0.93      0.91      8651\n",
      "\n",
      "\n",
      "Category: storm -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      7842\n",
      "           1       0.76      0.38      0.51       809\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      8651\n",
      "   macro avg       0.85      0.68      0.73      8651\n",
      "weighted avg       0.92      0.93      0.92      8651\n",
      "\n",
      "\n",
      "Category: fire -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      8556\n",
      "           1       0.60      0.03      0.06        95\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      8651\n",
      "   macro avg       0.79      0.52      0.53      8651\n",
      "weighted avg       0.99      0.99      0.98      8651\n",
      "\n",
      "\n",
      "Category: earthquake -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      7843\n",
      "           1       0.90      0.62      0.73       808\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      8651\n",
      "   macro avg       0.93      0.81      0.86      8651\n",
      "weighted avg       0.96      0.96      0.95      8651\n",
      "\n",
      "\n",
      "Category: cold -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      8480\n",
      "           1       0.80      0.09      0.17       171\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      8651\n",
      "   macro avg       0.89      0.55      0.58      8651\n",
      "weighted avg       0.98      0.98      0.97      8651\n",
      "\n",
      "\n",
      "Category: other_weather -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      8209\n",
      "           1       0.54      0.03      0.06       442\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      8651\n",
      "   macro avg       0.75      0.51      0.51      8651\n",
      "weighted avg       0.93      0.95      0.93      8651\n",
      "\n",
      "\n",
      "Category: direct_report -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.98      0.91      6970\n",
      "           1       0.78      0.31      0.44      1681\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      8651\n",
      "   macro avg       0.82      0.64      0.68      8651\n",
      "weighted avg       0.84      0.85      0.82      8651\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Scores for each category\n",
    "for i, col in enumerate(Y_test.columns):\n",
    "    print(f\"\\nCategory: {col} -----------------------------------\")\n",
    "    print(classification_report(Y_test.iloc[:, i], Y_pred[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (default)\n",
      "---------------------------\n",
      "Accuracy: 0.23084036527569068\n",
      "Precision: 0.8112696525300568\n",
      "Recall: 0.44635458312132004\n",
      "F1 Score: 0.5758698302541498\n"
     ]
    }
   ],
   "source": [
    "# Overall scores\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred, average='micro')\n",
    "precision = precision_score(Y_test, Y_pred, average='micro')\n",
    "recall = recall_score(Y_test, Y_pred, average='micro')\n",
    "print(\"Random Forest (default)\")\n",
    "print(\"-\"*27)\n",
    "print(f\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip..._score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=None))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify parameters for grid search\n",
    "parameters = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "#    'vect__max_df': (0.75, 1.0),\n",
    "#    'tfidf__use_idf': (True, False),\n",
    "#    'clf__estimator__n_estimators': [10, 50, 100, 200],\n",
    "#     'clf__estimator__min_samples_split': [2, 5, 10],\n",
    "#     'clf__estimator__max_depth': [3, 50, None],\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, scoring='accuracy', cv=3)\n",
    "cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv.estimator.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test model\n",
    "Show the accuracy, precision, and recall of the tuned model. We can further improve model performance by running grid search on the full parameter ranges defined above. For the scope of this project, I'm going to move on with this minimal tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions based on the trained model\n",
    "Y_pred = cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category: related -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.36      0.45      2034\n",
      "           1       0.82      0.92      0.87      6617\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      8651\n",
      "   macro avg       0.71      0.64      0.66      8651\n",
      "weighted avg       0.77      0.79      0.77      8651\n",
      "\n",
      "\n",
      "Category: request -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      7201\n",
      "           1       0.83      0.43      0.56      1450\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      8651\n",
      "   macro avg       0.86      0.71      0.75      8651\n",
      "weighted avg       0.88      0.89      0.87      8651\n",
      "\n",
      "\n",
      "Category: offer -----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angang\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8610\n",
      "           1       0.00      0.00      0.00        41\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      8651\n",
      "   macro avg       0.50      0.50      0.50      8651\n",
      "weighted avg       0.99      1.00      0.99      8651\n",
      "\n",
      "\n",
      "Category: aid_related -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.88      0.79      5044\n",
      "           1       0.74      0.50      0.60      3607\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      8651\n",
      "   macro avg       0.73      0.69      0.69      8651\n",
      "weighted avg       0.73      0.72      0.71      8651\n",
      "\n",
      "\n",
      "Category: medical_help -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      7957\n",
      "           1       0.64      0.08      0.14       694\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      8651\n",
      "   macro avg       0.78      0.54      0.55      8651\n",
      "weighted avg       0.90      0.92      0.89      8651\n",
      "\n",
      "\n",
      "Category: medical_products -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      8210\n",
      "           1       0.72      0.06      0.12       441\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      8651\n",
      "   macro avg       0.83      0.53      0.55      8651\n",
      "weighted avg       0.94      0.95      0.93      8651\n",
      "\n",
      "\n",
      "Category: search_and_rescue -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      8409\n",
      "           1       0.65      0.06      0.11       242\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      8651\n",
      "   macro avg       0.81      0.53      0.55      8651\n",
      "weighted avg       0.96      0.97      0.96      8651\n",
      "\n",
      "\n",
      "Category: security -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      8481\n",
      "           1       0.00      0.00      0.00       170\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      8651\n",
      "   macro avg       0.49      0.50      0.50      8651\n",
      "weighted avg       0.96      0.98      0.97      8651\n",
      "\n",
      "\n",
      "Category: military -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      8386\n",
      "           1       0.67      0.05      0.08       265\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      8651\n",
      "   macro avg       0.82      0.52      0.53      8651\n",
      "weighted avg       0.96      0.97      0.96      8651\n",
      "\n",
      "\n",
      "Category: child_alone -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8651\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      8651\n",
      "   macro avg       1.00      1.00      1.00      8651\n",
      "weighted avg       1.00      1.00      1.00      8651\n",
      "\n",
      "\n",
      "Category: water -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      8109\n",
      "           1       0.81      0.21      0.34       542\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      8651\n",
      "   macro avg       0.88      0.61      0.66      8651\n",
      "weighted avg       0.94      0.95      0.93      8651\n",
      "\n",
      "\n",
      "Category: food -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      7701\n",
      "           1       0.85      0.40      0.54       950\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      8651\n",
      "   macro avg       0.89      0.69      0.75      8651\n",
      "weighted avg       0.92      0.93      0.91      8651\n",
      "\n",
      "\n",
      "Category: shelter -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      7866\n",
      "           1       0.87      0.17      0.28       785\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      8651\n",
      "   macro avg       0.90      0.58      0.62      8651\n",
      "weighted avg       0.92      0.92      0.90      8651\n",
      "\n",
      "\n",
      "Category: clothing -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      8528\n",
      "           1       0.69      0.07      0.13       123\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      8651\n",
      "   macro avg       0.84      0.54      0.56      8651\n",
      "weighted avg       0.98      0.99      0.98      8651\n",
      "\n",
      "\n",
      "Category: money -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      8456\n",
      "           1       0.58      0.04      0.07       195\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      8651\n",
      "   macro avg       0.78      0.52      0.53      8651\n",
      "weighted avg       0.97      0.98      0.97      8651\n",
      "\n",
      "\n",
      "Category: missing_people -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      8547\n",
      "           1       0.00      0.00      0.00       104\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      8651\n",
      "   macro avg       0.49      0.50      0.50      8651\n",
      "weighted avg       0.98      0.99      0.98      8651\n",
      "\n",
      "\n",
      "Category: refugees -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      8344\n",
      "           1       0.63      0.04      0.07       307\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      8651\n",
      "   macro avg       0.80      0.52      0.53      8651\n",
      "weighted avg       0.95      0.97      0.95      8651\n",
      "\n",
      "\n",
      "Category: death -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      8240\n",
      "           1       0.81      0.15      0.25       411\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      8651\n",
      "   macro avg       0.88      0.57      0.61      8651\n",
      "weighted avg       0.95      0.96      0.94      8651\n",
      "\n",
      "\n",
      "Category: other_aid -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      7491\n",
      "           1       0.55      0.04      0.07      1160\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      8651\n",
      "   macro avg       0.71      0.52      0.50      8651\n",
      "weighted avg       0.83      0.87      0.81      8651\n",
      "\n",
      "\n",
      "Category: infrastructure_related -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      8100\n",
      "           1       0.62      0.01      0.02       551\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      8651\n",
      "   macro avg       0.78      0.50      0.49      8651\n",
      "weighted avg       0.92      0.94      0.91      8651\n",
      "\n",
      "\n",
      "Category: transport -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      8266\n",
      "           1       0.65      0.04      0.08       385\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      8651\n",
      "   macro avg       0.81      0.52      0.53      8651\n",
      "weighted avg       0.94      0.96      0.94      8651\n",
      "\n",
      "\n",
      "Category: buildings -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      8202\n",
      "           1       0.75      0.12      0.20       449\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      8651\n",
      "   macro avg       0.85      0.56      0.59      8651\n",
      "weighted avg       0.94      0.95      0.94      8651\n",
      "\n",
      "\n",
      "Category: electricity -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      8471\n",
      "           1       0.80      0.02      0.04       180\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      8651\n",
      "   macro avg       0.89      0.51      0.52      8651\n",
      "weighted avg       0.98      0.98      0.97      8651\n",
      "\n",
      "\n",
      "Category: tools -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      8596\n",
      "           1       0.00      0.00      0.00        55\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      8651\n",
      "   macro avg       0.50      0.50      0.50      8651\n",
      "weighted avg       0.99      0.99      0.99      8651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Category: hospitals -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      8569\n",
      "           1       0.00      0.00      0.00        82\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      8651\n",
      "   macro avg       0.50      0.50      0.50      8651\n",
      "weighted avg       0.98      0.99      0.99      8651\n",
      "\n",
      "\n",
      "Category: shops -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8615\n",
      "           1       0.00      0.00      0.00        36\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      8651\n",
      "   macro avg       0.50      0.50      0.50      8651\n",
      "weighted avg       0.99      1.00      0.99      8651\n",
      "\n",
      "\n",
      "Category: aid_centers -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      8543\n",
      "           1       0.00      0.00      0.00       108\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      8651\n",
      "   macro avg       0.49      0.50      0.50      8651\n",
      "weighted avg       0.98      0.99      0.98      8651\n",
      "\n",
      "\n",
      "Category: other_infrastructure -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      8279\n",
      "           1       0.20      0.00      0.01       372\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      8651\n",
      "   macro avg       0.58      0.50      0.49      8651\n",
      "weighted avg       0.92      0.96      0.94      8651\n",
      "\n",
      "\n",
      "Category: weather_related -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.89      6202\n",
      "           1       0.86      0.44      0.58      2449\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      8651\n",
      "   macro avg       0.84      0.71      0.73      8651\n",
      "weighted avg       0.83      0.82      0.80      8651\n",
      "\n",
      "\n",
      "Category: floods -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      7914\n",
      "           1       0.89      0.27      0.41       737\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      8651\n",
      "   macro avg       0.91      0.63      0.69      8651\n",
      "weighted avg       0.93      0.93      0.92      8651\n",
      "\n",
      "\n",
      "Category: storm -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      7842\n",
      "           1       0.77      0.31      0.45       809\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      8651\n",
      "   macro avg       0.85      0.65      0.70      8651\n",
      "weighted avg       0.92      0.93      0.91      8651\n",
      "\n",
      "\n",
      "Category: fire -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      8556\n",
      "           1       0.00      0.00      0.00        95\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      8651\n",
      "   macro avg       0.49      0.50      0.50      8651\n",
      "weighted avg       0.98      0.99      0.98      8651\n",
      "\n",
      "\n",
      "Category: earthquake -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      7843\n",
      "           1       0.89      0.68      0.77       808\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      8651\n",
      "   macro avg       0.93      0.83      0.87      8651\n",
      "weighted avg       0.96      0.96      0.96      8651\n",
      "\n",
      "\n",
      "Category: cold -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      8480\n",
      "           1       0.58      0.04      0.08       171\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      8651\n",
      "   macro avg       0.78      0.52      0.53      8651\n",
      "weighted avg       0.97      0.98      0.97      8651\n",
      "\n",
      "\n",
      "Category: other_weather -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      8209\n",
      "           1       0.67      0.02      0.04       442\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      8651\n",
      "   macro avg       0.81      0.51      0.51      8651\n",
      "weighted avg       0.94      0.95      0.93      8651\n",
      "\n",
      "\n",
      "Category: direct_report -----------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.91      6970\n",
      "           1       0.80      0.31      0.45      1681\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      8651\n",
      "   macro avg       0.83      0.65      0.68      8651\n",
      "weighted avg       0.84      0.85      0.82      8651\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Scores for each category\n",
    "for i, col in enumerate(Y_test.columns):\n",
    "    print(f\"\\nCategory: {col} -----------------------------------\")\n",
    "    print(classification_report(Y_test.iloc[:, i], Y_pred[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (tuned)\n",
      "---------------------------\n",
      "Accuracy: 0.2311871459946827\n",
      "Precision: 0.8113650070361187\n",
      "Recall: 0.4400668750454314\n",
      "F1 Score: 0.5706341164549802\n"
     ]
    }
   ],
   "source": [
    "# Overall scores\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred, average='micro')\n",
    "precision = precision_score(Y_test, Y_pred, average='micro')\n",
    "recall = recall_score(Y_test, Y_pred, average='micro')\n",
    "print(\"Random Forest (tuned)\")\n",
    "print(\"-\"*27)\n",
    "print(f\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving the model further\n",
    "* try other machine learning algorithms\n",
    "* try other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare different machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (default)\n",
      "---------------------------\n",
      "Accuracy: 0.22887527453473586\n",
      "Precision: 0.8084488448844884\n",
      "Recall: 0.44515519371956097\n",
      "F1 Score: 0.5741608850553159\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "# Build model pipeline\n",
    "pipeline_nb = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier(n_estimators=10))),\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline_nb.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions based on the trained model\n",
    "Y_pred = pipeline_nb.predict(X_test)\n",
    "\n",
    "# Overall scores\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred, average='micro')\n",
    "precision = precision_score(Y_test, Y_pred, average='micro')\n",
    "recall = recall_score(Y_test, Y_pred, average='micro')\n",
    "print(\"Random Forest (default)\")\n",
    "print(\"-\"*27)\n",
    "print(f\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angang\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:465: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes (default)\n",
      "---------------------------\n",
      "Accuracy: 0.16333371864524332\n",
      "Precision: 0.7817003431185665\n",
      "Recall: 0.37261030747982843\n",
      "F1 Score: 0.5046641561446258\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "# Build model pipeline\n",
    "pipeline_nb = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(MultinomialNB())),\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline_nb.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions based on the trained model\n",
    "Y_pred = pipeline_nb.predict(X_test)\n",
    "\n",
    "# Overall scores\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred, average='micro')\n",
    "precision = precision_score(Y_test, Y_pred, average='micro')\n",
    "recall = recall_score(Y_test, Y_pred, average='micro')\n",
    "print(\"Multinomial Naive Bayes (default)\")\n",
    "print(\"-\"*27)\n",
    "print(f\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree (default)\n",
      "---------------------------\n",
      "Accuracy: 0.14888452202057564\n",
      "Precision: 0.6122379474759706\n",
      "Recall: 0.588027913062441\n",
      "F1 Score: 0.599888765294772\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "# Build model pipeline\n",
    "pipeline_dt = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(DecisionTreeClassifier())),\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline_dt.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions based on the trained model\n",
    "Y_pred = pipeline_dt.predict(X_test)\n",
    "\n",
    "# Overall scores\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred, average='micro')\n",
    "precision = precision_score(Y_test, Y_pred, average='micro')\n",
    "recall = recall_score(Y_test, Y_pred, average='micro')\n",
    "print(\"Decision Tree (default)\")\n",
    "print(\"-\"*27)\n",
    "print(f\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, Random Forest performs the best among these algorithms, so Random Forest is chosen for further tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add other features besides TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom transformer\n",
    "class StartingVerbExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def starting_verb(self, text):\n",
    "        sentence_list = nltk.sent_tokenize(text)\n",
    "        for sentence in sentence_list:\n",
    "            if len(tokenize(sentence))>0:\n",
    "                pos_tags = nltk.pos_tag(tokenize(sentence))\n",
    "                first_word, first_tag = pos_tags[0]\n",
    "                if first_tag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']:\n",
    "                    return 1\n",
    "        return 0\n",
    "\n",
    "    # Fit method\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    # Transform method\n",
    "    def transform(self, X):\n",
    "        X_tagged = pd.Series(X, name='starting_verb').apply(self.starting_verb)\n",
    "        return pd.DataFrame(X_tagged)\n",
    "    \n",
    "# # Sanity check\n",
    "# starting_verb = StartingVerbExtractor()\n",
    "# starting_verb.transform(X.iloc[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom transformer\n",
    "entity_list = ['TIME', 'PERSON', 'GPE', 'DATE', 'NORP', 'MONEY', 'ORG', 'QUANTITY', 'CARDINAL', 'PERCENT', \n",
    "               'LOC', 'PRODUCT', 'FAC', 'ORDINAL', 'WORK_OF_ART', 'LANGUAGE', 'LAW', 'EVENT']\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "class NamedEntityExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def named_entities(self, text):\n",
    "        doc = nlp(text)\n",
    "        labels = [ent.label_ for ent in doc.ents]\n",
    "        labels_count = Counter(labels)\n",
    "        for ent in entity_list:\n",
    "            if ent not in labels_count.keys():\n",
    "                labels_count[ent] = 0\n",
    "        return labels_count\n",
    "\n",
    "    # Fit method\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    # Transform method\n",
    "    def transform(self, X):\n",
    "        X_ent = X.apply(self.named_entities).apply(pd.Series)\n",
    "        X_ent = X_ent.fillna(0)\n",
    "        X_ent = X_ent[entity_list]\n",
    "        return X_ent\n",
    "    \n",
    "# # Sanity check\n",
    "# named_entity = NamedEntityExtractor()\n",
    "# named_entity.transform(X.iloc[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model pipeline\n",
    "pipeline_rf_new = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "\n",
    "        ('text_pipeline', Pipeline([\n",
    "            ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ])),\n",
    "\n",
    "        ('starting_verb', StartingVerbExtractor()), # this is a custom transformer\n",
    "        \n",
    "        ('named_entity', NamedEntityExtractor()) # this is a custom transformer\n",
    "    ])),\n",
    "\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier(n_estimators=10))),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (default)\n",
      "---------------------------\n",
      "Accuracy: 0.24135938041844873\n",
      "Precision: 0.8101831729276622\n",
      "Recall: 0.47423130042887257\n",
      "F1 Score: 0.5982713954927898\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "pipeline_rf_new.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions based on the trained model\n",
    "Y_pred = pipeline_rf_new.predict(X_test)\n",
    "\n",
    "# Overall scores\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred, average='micro')\n",
    "precision = precision_score(Y_test, Y_pred, average='micro')\n",
    "recall = recall_score(Y_test, Y_pred, average='micro')\n",
    "print(\"Random Forest (default)\")\n",
    "print(\"-\"*27)\n",
    "print(f\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the performance is better than using TF-IDF alone. Therefore, I'm going to use the new pipeline to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_rf_new.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('text_pipeline', Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, ma..._score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=None))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'features__text_pipeline__vect__ngram_range': ((1, 1), (1, 2))},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify parameters for grid search\n",
    "parameters = {\n",
    "    'features__text_pipeline__vect__ngram_range': ((1, 1), (1, 2)),\n",
    "#     'features__text_pipeline__vect__max_df': (0.75, 1.0),\n",
    "#     'features__text_pipeline__tfidf__use_idf': (True, False),\n",
    "#     'clf__estimator__n_estimators': [10, 50, 100, 200],\n",
    "#     'clf__estimator__min_samples_split': [2, 5, 10],\n",
    "#     'clf__estimator__max_depth': [3, 50, None],\n",
    "#     'features__transformer_weights': (\n",
    "#         {'text_pipeline': 1, 'starting_verb': 1, 'named_entity': 1},\n",
    "#         {'text_pipeline': 0.5, 'starting_verb': 1, 'named_entity': 1},\n",
    "#         {'text_pipeline': 1, 'starting_verb': 0.5, 'named_entity': 0.5},\n",
    "#     )\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline_rf_new, param_grid=parameters, scoring='accuracy', cv=3)\n",
    "cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv.estimator.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further improve model performance by running grid search on the full parameter ranges defined above. For the scope of this project, I'm going to move on with this minimal tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (default)\n",
      "---------------------------\n",
      "Accuracy: 0.2491041498092706\n",
      "Precision: 0.8092849715578935\n",
      "Recall: 0.4808824598386276\n",
      "F1 Score: 0.603287508834325\n"
     ]
    }
   ],
   "source": [
    "# Make predictions based on the trained model\n",
    "Y_pred = cv.predict(X_test)\n",
    "\n",
    "# Overall scores\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred, average='micro')\n",
    "precision = precision_score(Y_test, Y_pred, average='micro')\n",
    "recall = recall_score(Y_test, Y_pred, average='micro')\n",
    "print(\"Random Forest (default)\")\n",
    "print(\"-\"*27)\n",
    "print(f\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model to disk\n",
    "filename = 'classifier.pkl'\n",
    "# pickle.dump(cv, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is then converted to `train_classifier.py`, which runs the steps above to train the classifier based on user inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
